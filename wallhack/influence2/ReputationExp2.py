"""
Use the DBLP dataset to recommend experts. Let's just look at the terms and topics 
generated by the models. 
"""
import gc 
import os
import numpy 
import logging 
import sys 
import argparse
import scipy.io 
import matplotlib 
matplotlib.use("GTK3Agg")
import matplotlib.pyplot as plt 
from exp.influence2.GraphRanker import GraphRanker 
from exp.influence2.RankAggregator import RankAggregator
from exp.influence2.ArnetMinerDataset import ArnetMinerDataset
from apgl.util.Latex import Latex 
from apgl.util.Evaluator import Evaluator

logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
numpy.set_printoptions(suppress=True, precision=3, linewidth=160)
numpy.random.seed(21)

parser = argparse.ArgumentParser(description='Run reputation evaluation experiments')
parser.add_argument("-r", "--runLDA", action="store_true", help="Run Latent Dirchlet Allocation")
args = parser.parse_args()

averagePrecisionN = 50 
similarityCutoff = 0.30
ns = numpy.arange(5, 105, 5)
runLSI = not args.runLDA

dataset = ArnetMinerDataset(runLSI=runLSI) 
#dataset.dataFilename = dataset.dataDir + "DBLP-citation-100000.txt"

#dataset.dataFilename = dataset.dataDir + "DBLP-citation-1000000.txt"
dataset.dataFilename = dataset.dataDir + "DBLP-citation-1000000.txt"
#dataset.dataFilename = dataset.dataDir + "DBLP-citation-7000000.txt"
#dataset.dataFilename = dataset.dataDir + "DBLP-citation-Feb21.txt" 
dataset.overwriteGraph = True
dataset.overwriteModel = True

dataset.overwriteVectoriser = True 
dataset.vectoriseDocuments()
dataset.loadVectoriser()


X = scipy.io.mmread(dataset.docTermMatrixFilename + ".mtx")
X = X.tocsc()
X.data[:] = 1

print(numpy.max(X.data), numpy.min(X.data))

rowSums = numpy.array(X.sum(0), numpy.int).flatten()
colSums = numpy.array(X.sum(1), numpy.int).flatten()

sortedIndsColSums = numpy.argsort(rowSums)

featureNames = dataset.vectoriser.get_feature_names()
#Print out lowest frequency terms 
for i in sortedIndsColSums[0:100]: 
    print(featureNames[i], rowSums[i])

sortedRowSums = numpy.sort(rowSums)/float(X.shape[0])
sortedColSums = numpy.sort(colSums)/float(X.shape[1])

plt.figure(0)
plt.plot(numpy.arange(sortedRowSums.shape[0]), numpy.log(sortedRowSums))
plt.ylabel("Proportion of documents")
plt.xlabel("Frequency")

plt.figure(1)
plt.plot(numpy.arange(sortedColSums.shape[0]), sortedColSums)
plt.ylabel("Proportion of terms")
plt.xlabel("Frequency")

plt.show()